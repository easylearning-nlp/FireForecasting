{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T13:34:08.530941Z",
     "iopub.status.busy": "2022-09-28T13:34:08.530524Z",
     "iopub.status.idle": "2022-09-28T13:34:09.493962Z",
     "shell.execute_reply": "2022-09-28T13:34:09.492918Z",
     "shell.execute_reply.started": "2022-09-28T13:34:08.530916Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import functools\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.metrics import mean_squared_log_error as msle\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T13:34:09.495985Z",
     "iopub.status.busy": "2022-09-28T13:34:09.495432Z",
     "iopub.status.idle": "2022-09-28T13:34:09.499361Z",
     "shell.execute_reply": "2022-09-28T13:34:09.498735Z",
     "shell.execute_reply.started": "2022-09-28T13:34:09.495956Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DATA_PATH = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T13:34:09.500695Z",
     "iopub.status.busy": "2022-09-28T13:34:09.500496Z",
     "iopub.status.idle": "2022-09-28T13:34:09.946022Z",
     "shell.execute_reply": "2022-09-28T13:34:09.945192Z",
     "shell.execute_reply.started": "2022-09-28T13:34:09.500676Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_daily = pd.read_csv(DATA_PATH + 'daily_dataset.csv')\n",
    "df_min = pd.read_csv(DATA_PATH + 'per5min_dataset.csv')\n",
    "df_hour = pd.read_csv(DATA_PATH + 'hourly_dataset_preprocessed.csv')\n",
    "df_test = pd.read_csv(DATA_PATH + 'test_public.csv')\n",
    "df_sub = pd.read_csv(DATA_PATH + 'sample_submission.csv')\n",
    "df_weather = pd.read_csv(DATA_PATH + 'weather.csv')\n",
    "df_epidemic = pd.read_csv(DATA_PATH + 'epidemic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T13:34:10.397871Z",
     "iopub.status.busy": "2022-09-28T13:34:10.397346Z",
     "iopub.status.idle": "2022-09-28T13:34:10.400235Z",
     "shell.execute_reply": "2022-09-28T13:34:10.399659Z",
     "shell.execute_reply.started": "2022-09-28T13:34:10.397852Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SEQ_LEN = 168"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T13:34:10.401120Z",
     "iopub.status.busy": "2022-09-28T13:34:10.400933Z",
     "iopub.status.idle": "2022-09-28T13:34:10.409727Z",
     "shell.execute_reply": "2022-09-28T13:34:10.409166Z",
     "shell.execute_reply.started": "2022-09-28T13:34:10.401103Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2022-05-01 01:00:00',\n",
       " '2022-05-08 00:00:00',\n",
       " '2022-06-01 01:00:00',\n",
       " '2022-06-08 00:00:00',\n",
       " '2022-07-21 01:00:00',\n",
       " '2022-07-28 00:00:00',\n",
       " '2022-08-21 01:00:00',\n",
       " '2022-08-28 00:00:00']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_list1 = df_test.groupby('train or test')['time'].first().reset_index()\n",
    "test_list1 = test_list1['time'].values.tolist()\n",
    "test_list2 = df_test.groupby('train or test')['time'].last().reset_index()\n",
    "test_list2 = test_list2['time'].values.tolist()\n",
    "test_list1.extend(test_list2)\n",
    "test_list1.sort()\n",
    "test_list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T13:34:10.410948Z",
     "iopub.status.busy": "2022-09-28T13:34:10.410472Z",
     "iopub.status.idle": "2022-09-28T13:34:10.415398Z",
     "shell.execute_reply": "2022-09-28T13:34:10.414833Z",
     "shell.execute_reply.started": "2022-09-28T13:34:10.410929Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['flow_1',\n",
       "  'flow_2',\n",
       "  'flow_3',\n",
       "  'flow_4',\n",
       "  'flow_5',\n",
       "  'flow_6',\n",
       "  'flow_7',\n",
       "  'flow_8',\n",
       "  'flow_9',\n",
       "  'flow_10',\n",
       "  'flow_11',\n",
       "  'flow_12',\n",
       "  'flow_13',\n",
       "  'flow_14',\n",
       "  'flow_15',\n",
       "  'flow_16',\n",
       "  'flow_17',\n",
       "  'flow_18',\n",
       "  'flow_19',\n",
       "  'flow_20',\n",
       "  'day',\n",
       "  'hour',\n",
       "  'dayofweek'],\n",
       " ['flow_1',\n",
       "  'flow_2',\n",
       "  'flow_3',\n",
       "  'flow_4',\n",
       "  'flow_5',\n",
       "  'flow_6',\n",
       "  'flow_7',\n",
       "  'flow_8',\n",
       "  'flow_9',\n",
       "  'flow_10',\n",
       "  'flow_11',\n",
       "  'flow_12',\n",
       "  'flow_13',\n",
       "  'flow_14',\n",
       "  'flow_15',\n",
       "  'flow_16',\n",
       "  'flow_17',\n",
       "  'flow_18',\n",
       "  'flow_19',\n",
       "  'flow_20'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COLUMNS_Y = ['flow_{}'.format(i) for i in range(1, 21)]\n",
    "COLUMNS_X = COLUMNS_Y + ['day', 'hour', 'dayofweek']\n",
    "COLUMNS_X, COLUMNS_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T13:34:10.416531Z",
     "iopub.status.busy": "2022-09-28T13:34:10.416164Z",
     "iopub.status.idle": "2022-09-28T13:34:10.420922Z",
     "shell.execute_reply": "2022-09-28T13:34:10.420326Z",
     "shell.execute_reply.started": "2022-09-28T13:34:10.416511Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_time_feat(data):\n",
    "    data['time'] = pd.to_datetime(data['time'])\n",
    "    data['day'] = data['time'].dt.day\n",
    "    data['hour'] = data['time'].dt.hour\n",
    "    data['minute'] = data['time'].dt.minute\n",
    "    data['dayofweek'] = data['time'].dt.dayofweek\n",
    "    return data.sort_values('time').reset_index(drop=True)\n",
    "\n",
    "def add_other_feat(data, columns):\n",
    "    data['flow_sum'] = data[columns].sum()\n",
    "    data['flow_median'] = data[columns].median()\n",
    "    data['flow_mean'] = data[columns].mean()\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T13:34:10.422088Z",
     "iopub.status.busy": "2022-09-28T13:34:10.421656Z",
     "iopub.status.idle": "2022-09-28T13:34:10.431548Z",
     "shell.execute_reply": "2022-09-28T13:34:10.430973Z",
     "shell.execute_reply.started": "2022-09-28T13:34:10.422069Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_hour = add_time_feat(df_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T13:34:10.451019Z",
     "iopub.status.busy": "2022-09-28T13:34:10.450658Z",
     "iopub.status.idle": "2022-09-28T13:34:10.458365Z",
     "shell.execute_reply": "2022-09-28T13:34:10.457787Z",
     "shell.execute_reply.started": "2022-09-28T13:34:10.450999Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Trans:\n",
    "    def __init__(self, data, name):\n",
    "        self.min = max(0, np.percentile(data, 1))\n",
    "        self.max = np.percentile(data, 99)\n",
    "        self.base = self.max-self.min\n",
    "\n",
    "    def transform(self, data, scale=True):\n",
    "        _data = np.clip(data, self.min, self.max)\n",
    "        if not scale:\n",
    "            return _data\n",
    "        return (_data-self.min)/self.base\n",
    "\n",
    "class TransUtil:\n",
    "    def __init__(self, data, exclude_cols=None):\n",
    "        self.columns = data.columns\n",
    "        self.exclude_cols = exclude_cols\n",
    "        self.trans = {}\n",
    "        for c in self.columns:\n",
    "            if data[c].dtype not in [int, float]:\n",
    "                print('column \"{}\" not init trans...'.format(c))\n",
    "                continue\n",
    "\n",
    "            if exclude_cols is None or (exclude_cols is not None and c not in exclude_cols):\n",
    "                print('init trans column...', c)\n",
    "                self.trans[c] = Trans(data[c].fillna(method='backfill').fillna(method='ffill'), c)\n",
    "\n",
    "    def transform(self, data, col_name, scale=True):\n",
    "        if self.exclude_cols is not None and col_name in self.exclude_cols:\n",
    "            return data\n",
    "\n",
    "        for t in self.trans:\n",
    "            if t.startswith(col_name):\n",
    "                return self.trans[t].transform(data, scale=scale)\n",
    "        \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T13:34:10.459597Z",
     "iopub.status.busy": "2022-09-28T13:34:10.459133Z",
     "iopub.status.idle": "2022-09-28T13:34:10.482790Z",
     "shell.execute_reply": "2022-09-28T13:34:10.482168Z",
     "shell.execute_reply.started": "2022-09-28T13:34:10.459578Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column \"time\" not init trans...\n",
      "init trans column... flow_1\n",
      "init trans column... flow_2\n",
      "init trans column... flow_3\n",
      "init trans column... flow_4\n",
      "init trans column... flow_5\n",
      "init trans column... flow_6\n",
      "init trans column... flow_7\n",
      "init trans column... flow_8\n",
      "init trans column... flow_9\n",
      "init trans column... flow_10\n",
      "init trans column... flow_11\n",
      "init trans column... flow_12\n",
      "init trans column... flow_13\n",
      "init trans column... flow_14\n",
      "init trans column... flow_15\n",
      "init trans column... flow_16\n",
      "init trans column... flow_17\n",
      "init trans column... flow_18\n",
      "init trans column... flow_19\n",
      "init trans column... flow_20\n",
      "column \"train or test\" not init trans...\n",
      "init trans column... day\n",
      "init trans column... hour\n",
      "init trans column... minute\n",
      "init trans column... dayofweek\n"
     ]
    }
   ],
   "source": [
    "trans_util = TransUtil(df_hour, exclude_cols=None) # 数据标准化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T13:34:10.484029Z",
     "iopub.status.busy": "2022-09-28T13:34:10.483578Z",
     "iopub.status.idle": "2022-09-28T13:34:10.490326Z",
     "shell.execute_reply": "2022-09-28T13:34:10.489738Z",
     "shell.execute_reply.started": "2022-09-28T13:34:10.484010Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_xy_pair(data, seq_len, trans_util, columns_x, columns_y):\n",
    "    data_x = pd.DataFrame()\n",
    "    for c in columns_x:\n",
    "        data_x[c] = trans_util.transform(data[c].fillna(data[c].median()), c)\n",
    "\n",
    "    data_y = pd.DataFrame()\n",
    "    for c in columns_y:\n",
    "        data_y[c] = trans_util.transform(data[c].fillna(data[c].median()), c, scale=False)\n",
    "\n",
    "    data_x = data_x.values\n",
    "    data_y = data_y.values\n",
    "    \n",
    "    print(data_x.shape, data_y.shape)\n",
    "\n",
    "    d_x = []\n",
    "    d_y = []\n",
    "    for i in range(len(data_x)-seq_len*2+1):\n",
    "        _x = data_x[i:i+seq_len]\n",
    "        _y = data_y[i+seq_len:i+seq_len+seq_len]\n",
    "\n",
    "        assert len(_x) == len(_y) == seq_len, (_x, _y, _x.shape, _y.shape, i, len(data_x))\n",
    "\n",
    "        d_x.append(_x.T)\n",
    "        d_y.append(_y.T)\n",
    "\n",
    "    return np.asarray(d_x).transpose((0, 2, 1)), np.asarray(d_y).transpose((0, 2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T13:34:10.491210Z",
     "iopub.status.busy": "2022-09-28T13:34:10.491032Z",
     "iopub.status.idle": "2022-09-28T13:34:10.650966Z",
     "shell.execute_reply": "2022-09-28T13:34:10.650136Z",
     "shell.execute_reply.started": "2022-09-28T13:34:10.491193Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5736, 23) (5736, 20)\n"
     ]
    }
   ],
   "source": [
    "data_x, data_y = generate_xy_pair(df_hour, seq_len=SEQ_LEN, trans_util=trans_util, columns_x=COLUMNS_X, columns_y=COLUMNS_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T13:34:10.652583Z",
     "iopub.status.busy": "2022-09-28T13:34:10.652025Z",
     "iopub.status.idle": "2022-09-28T13:34:10.656693Z",
     "shell.execute_reply": "2022-09-28T13:34:10.656084Z",
     "shell.execute_reply.started": "2022-09-28T13:34:10.652557Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5401, 168, 23), (5401, 168, 20))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_x.shape, data_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T13:34:10.658050Z",
     "iopub.status.busy": "2022-09-28T13:34:10.657554Z",
     "iopub.status.idle": "2022-09-28T13:34:10.663020Z",
     "shell.execute_reply": "2022-09-28T13:34:10.662445Z",
     "shell.execute_reply.started": "2022-09-28T13:34:10.658029Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.19510716, 0.2526096 , 0.26320132, ..., 0.        , 0.04347826,\n",
       "         0.83333333],\n",
       "        [0.11625556, 0.13569937, 0.12541254, ..., 0.        , 0.08695652,\n",
       "         0.83333333],\n",
       "        [0.06570966, 0.04175365, 0.05033003, ..., 0.        , 0.13043478,\n",
       "         0.83333333],\n",
       "        ...,\n",
       "        [0.63687829, 0.98538622, 0.92739274, ..., 0.2       , 0.95652174,\n",
       "         0.66666667],\n",
       "        [0.92094622, 0.6993737 , 0.67986799, ..., 0.2       , 1.        ,\n",
       "         0.66666667],\n",
       "        [0.26991508, 0.44050104, 0.38118812, ..., 0.23333333, 0.        ,\n",
       "         0.83333333]]),\n",
       " array([[ 23.6  ,  12.2  ,  40.6  , ...,   3.932,   1.15 ,   1.4  ],\n",
       "        [ 15.6  ,   5.   ,  32.6  , ...,   1.575,   0.509,   0.3  ],\n",
       "        [ 12.4  ,   3.9  ,  25.1  , ...,   1.042,   0.394,   0.3  ],\n",
       "        ...,\n",
       "        [ 71.3  ,  46.3  , 133.3  , ...,  14.968,   6.192,   4.8  ],\n",
       "        [ 60.7  ,  37.   , 105.5  , ...,  12.944,   5.072,   4.   ],\n",
       "        [ 35.   ,  19.8  ,  67.5  , ...,   8.908,   2.912,   2.4  ]]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_x[0], data_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T13:34:10.664292Z",
     "iopub.status.busy": "2022-09-28T13:34:10.663782Z",
     "iopub.status.idle": "2022-09-28T13:34:10.674191Z",
     "shell.execute_reply": "2022-09-28T13:34:10.673604Z",
     "shell.execute_reply.started": "2022-09-28T13:34:10.664272Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 根据每段测试集将对应的训练数据/测试数据的idx提取出来\n",
    "_train_idx_1 = df_hour[df_hour['time']<test_list1[0]].index.values.tolist()\n",
    "_train_idx_2 = df_hour[(df_hour['time']>test_list1[1])&(df_hour['time']<test_list1[2])].index.values.tolist()\n",
    "_train_idx_3 = df_hour[(df_hour['time']>test_list1[3])&(df_hour['time']<test_list1[4])].index.values.tolist()\n",
    "_train_idx_4 = df_hour[(df_hour['time']>test_list1[5])&(df_hour['time']<test_list1[6])].index.values.tolist()\n",
    "\n",
    "# 每一段数据包括上一段时间\n",
    "train_idx_1 = _train_idx_1[:-SEQ_LEN*2]\n",
    "train_idx_2 = train_idx_1 + _train_idx_2[:-SEQ_LEN*2]\n",
    "train_idx_3 = train_idx_2 + _train_idx_3[:-SEQ_LEN*2]\n",
    "train_idx_4 = train_idx_3 + _train_idx_4[:-SEQ_LEN*2]\n",
    "\n",
    "test_idx_1 = _train_idx_1[-SEQ_LEN]\n",
    "test_idx_2 = _train_idx_2[-SEQ_LEN]\n",
    "test_idx_3 = _train_idx_3[-SEQ_LEN]\n",
    "test_idx_4 = _train_idx_4[-SEQ_LEN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T13:34:10.675428Z",
     "iopub.status.busy": "2022-09-28T13:34:10.674945Z",
     "iopub.status.idle": "2022-09-28T13:34:10.679049Z",
     "shell.execute_reply": "2022-09-28T13:34:10.678484Z",
     "shell.execute_reply.started": "2022-09-28T13:34:10.675409Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2880, 576, 1032, 576)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(_train_idx_1), len(_train_idx_2), len(_train_idx_3), len(_train_idx_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T13:34:10.683634Z",
     "iopub.status.busy": "2022-09-28T13:34:10.683243Z",
     "iopub.status.idle": "2022-09-28T13:34:10.687303Z",
     "shell.execute_reply": "2022-09-28T13:34:10.686734Z",
     "shell.execute_reply.started": "2022-09-28T13:34:10.683615Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2544, 2784, 3480, 3720)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_idx_1), len(train_idx_2), len(train_idx_3), len(train_idx_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T13:34:10.688545Z",
     "iopub.status.busy": "2022-09-28T13:34:10.688056Z",
     "iopub.status.idle": "2022-09-28T13:34:10.691897Z",
     "shell.execute_reply": "2022-09-28T13:34:10.691329Z",
     "shell.execute_reply.started": "2022-09-28T13:34:10.688526Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2712, 3456, 4656, 5400)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_idx_1, test_idx_2, test_idx_3, test_idx_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T13:34:10.693121Z",
     "iopub.status.busy": "2022-09-28T13:34:10.692649Z",
     "iopub.status.idle": "2022-09-28T13:34:10.928257Z",
     "shell.execute_reply": "2022-09-28T13:34:10.927430Z",
     "shell.execute_reply.started": "2022-09-28T13:34:10.693102Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_x_1 = data_x[train_idx_1]\n",
    "train_y_1 = data_y[train_idx_1]\n",
    "train_x_2 = data_x[train_idx_2]\n",
    "train_y_2 = data_y[train_idx_2]\n",
    "train_x_3 = data_x[train_idx_3]\n",
    "train_y_3 = data_y[train_idx_3]\n",
    "train_x_4 = data_x[train_idx_4]\n",
    "train_y_4 = data_y[train_idx_4]\n",
    "\n",
    "test_x_1 = data_x[test_idx_1]\n",
    "test_x_2 = data_x[test_idx_2]\n",
    "test_x_3 = data_x[test_idx_3]\n",
    "test_x_4 = data_x[test_idx_4]\n",
    "\n",
    "FEATURE_SIZE = train_x_1.shape[-1]\n",
    "OUTPUT_SIZE = train_y_1.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T13:34:10.929972Z",
     "iopub.status.busy": "2022-09-28T13:34:10.929378Z",
     "iopub.status.idle": "2022-09-28T13:34:10.934134Z",
     "shell.execute_reply": "2022-09-28T13:34:10.933526Z",
     "shell.execute_reply.started": "2022-09-28T13:34:10.929946Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2544, 168, 23), (2544, 168, 20), (168, 23))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_1.shape, train_y_1.shape, test_x_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T13:34:10.935393Z",
     "iopub.status.busy": "2022-09-28T13:34:10.935191Z",
     "iopub.status.idle": "2022-09-28T13:34:12.249885Z",
     "shell.execute_reply": "2022-09-28T13:34:12.248943Z",
     "shell.execute_reply.started": "2022-09-28T13:34:10.935374Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import paddle\n",
    "import paddle.nn as nn\n",
    "import paddle.nn.functional as F\n",
    "\n",
    "class Tt(nn.Layer):\n",
    "    def __init__(self,\n",
    "                 seq_len,\n",
    "                 feature_size,\n",
    "                 output_size,\n",
    "                 use_model='lstm',\n",
    "                 hidden_size=576,\n",
    "                 num_hidden_layers=6,\n",
    "                 num_attention_heads=6,\n",
    "                 intermediate_size=3072,\n",
    "                 hidden_act=\"gelu\",\n",
    "                 hidden_dropout_prob=0.1,\n",
    "                 attention_probs_dropout_prob=0.1,\n",
    "                 max_position_embeddings=512,\n",
    "                 max_hour=25,\n",
    "                 max_min=61,\n",
    "                 max_dow=8,\n",
    "                 max_ts=1441):\n",
    "        super(Tt, self).__init__()\n",
    "\n",
    "        self.use_model = use_model\n",
    "        self.feature_size = feature_size\n",
    "\n",
    "        # 如果有相应的时间embedding则可以使用\n",
    "        self.th_embeddings = nn.Embedding(max_hour, hidden_size)\n",
    "        self.tm_embeddings = nn.Embedding(max_min, hidden_size)\n",
    "        self.td_embeddings = nn.Embedding(max_dow, hidden_size)\n",
    "        self.tt_embeddings = nn.Embedding(max_ts, hidden_size)\n",
    "\n",
    "        # 位置编码\n",
    "        self.position_embeddings = nn.Embedding(max_position_embeddings, hidden_size)\n",
    "        self.layer_norm = nn.LayerNorm(hidden_size)\n",
    "        self.fc_inputs = nn.Linear(feature_size, hidden_size)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            hidden_size,\n",
    "            num_attention_heads,\n",
    "            intermediate_size,\n",
    "            dropout=hidden_dropout_prob,\n",
    "            activation=hidden_act,\n",
    "            attn_dropout=attention_probs_dropout_prob,\n",
    "            act_dropout=0)\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_hidden_layers)\n",
    "\n",
    "        self.lstm = paddle.nn.LSTM(input_size=hidden_size, hidden_size=hidden_size, num_layers=2)\n",
    "\n",
    "        self.fc_output_1 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc_output_2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc_output_3 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self,\n",
    "                inputs,\n",
    "                inputs_th=None,\n",
    "                inputs_tm=None,\n",
    "                inputs_td=None,\n",
    "                inputs_tt=None,\n",
    "                position_ids=None,\n",
    "                attention_mask=None):\n",
    "\n",
    "        if position_ids is None:\n",
    "            ones = paddle.ones(inputs.shape[:2], dtype=\"int64\")\n",
    "            seq_length = paddle.cumsum(ones, axis=1)\n",
    "            position_ids = seq_length - ones\n",
    "            position_ids.stop_gradient = True\n",
    "\n",
    "        position_embeddings = self.position_embeddings(position_ids)\n",
    "\n",
    "        inputs = self.fc_inputs(inputs)\n",
    "        inputs = nn.Tanh()(inputs)\n",
    "\n",
    "        inputs = inputs + position_embeddings\n",
    "\n",
    "        # 如果有相应的时间embedding则可以使用\n",
    "        if inputs_th is not None:\n",
    "            inputs += self.th_embeddings(inputs_th)\n",
    "        \n",
    "        if inputs_tm is not None:\n",
    "            inputs += self.tm_embeddings(inputs_tm)\n",
    "\n",
    "        if inputs_td is not None:\n",
    "            inputs += self.td_embeddings(inputs_td)\n",
    "\n",
    "        if inputs_tt is not None:\n",
    "            inputs += self.tt_embeddings(inputs_tt)\n",
    "\n",
    "        inputs = self.layer_norm(inputs)\n",
    "\n",
    "        # 选择使用LSTM或者Transformer\n",
    "        if self.use_model == 'lstm':\n",
    "            encoder_outputs, (h, c) = self.lstm(inputs)\n",
    "        elif self.use_model == 'transformer':\n",
    "            if attention_mask is None:\n",
    "                attention_mask = paddle.unsqueeze(\n",
    "                    (paddle.zeros(inputs.shape[:2])).astype(\n",
    "                        self.fc_inputs.weight.dtype) * -1e4,\n",
    "                    axis=[1, 2])\n",
    "\n",
    "            encoder_outputs = self.encoder(\n",
    "                inputs,\n",
    "                src_mask=attention_mask)\n",
    "\n",
    "        output = self.fc_output_1(encoder_outputs)\n",
    "        output = nn.ReLU()(output)\n",
    "        output = self.fc_output_2(output)\n",
    "        output = self.fc_output_3(output)\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T13:34:12.251742Z",
     "iopub.status.busy": "2022-09-28T13:34:12.251146Z",
     "iopub.status.idle": "2022-09-28T13:34:13.186081Z",
     "shell.execute_reply": "2022-09-28T13:34:13.185245Z",
     "shell.execute_reply.started": "2022-09-28T13:34:12.251714Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import paddle\n",
    "import paddle.nn.functional as F\n",
    "from paddle.metric import Accuracy\n",
    "from paddle.io import DataLoader, BatchSampler\n",
    "from paddlenlp.datasets import MapDataset\n",
    "from paddlenlp.data import DataCollatorWithPadding\n",
    "from paddlenlp.data import Dict, Stack, Pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T13:34:13.187897Z",
     "iopub.status.busy": "2022-09-28T13:34:13.187208Z",
     "iopub.status.idle": "2022-09-28T13:34:13.194806Z",
     "shell.execute_reply": "2022-09-28T13:34:13.194200Z",
     "shell.execute_reply.started": "2022-09-28T13:34:13.187866Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_score(y_true, y_pred):\n",
    "    return 1/(1+msle(np.clip(np.reshape(y_true, -1), 0, None), np.clip(np.reshape(y_pred, -1), 0, None)))\n",
    "\n",
    "def eval_model(model, data_loader):\n",
    "    model.eval()\n",
    "\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    for step, batch in enumerate(data_loader, start=1):\n",
    "        data = batch['data'].astype('float32')\n",
    "        label = batch['label'].astype('float32')\n",
    "\n",
    "        # 计算模型输出\n",
    "        output = model(inputs=data)\n",
    "        y_pred.extend(output.numpy())\n",
    "        y_true.extend(label.numpy())\n",
    "    \n",
    "    score = calc_score(y_true, y_pred)\n",
    "    model.train()\n",
    "    return score\n",
    "\n",
    "def make_data_loader(data_x, idx, batch_size, data_y=None, shuffle=False):\n",
    "\n",
    "    data = [{\n",
    "        'data': data_x[i], \n",
    "        'label': 0 if data_y is None else data_y[i]} \n",
    "        for i in idx]\n",
    "    ds = MapDataset(data)\n",
    "    batch_sampler = BatchSampler(ds, batch_size=batch_size, shuffle=shuffle)\n",
    "    return DataLoader(dataset=ds, batch_sampler=batch_sampler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T13:34:13.196017Z",
     "iopub.status.busy": "2022-09-28T13:34:13.195824Z",
     "iopub.status.idle": "2022-09-28T13:34:13.206290Z",
     "shell.execute_reply": "2022-09-28T13:34:13.205695Z",
     "shell.execute_reply.started": "2022-09-28T13:34:13.196000Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "EPOCHS = 30\n",
    "BATCH_SIZE = 256\n",
    "CKPT_DIR = 'work/output'\n",
    "K_FOLD = 5\n",
    "epoch_base = 0\n",
    "step_eval = 5\n",
    "step_log = 100\n",
    "\n",
    "def do_train(train_x, train_y, prefix):\n",
    "    print('-'*20)\n",
    "    print('training ...', prefix)\n",
    "    print('train x:', np.shape(train_x), 'train y:', np.shape(train_y))\n",
    "\n",
    "    paddle.seed(2022)\n",
    "\n",
    "    for kfold, tv_idx in enumerate(KFold(n_splits=K_FOLD, shuffle=True, random_state=2022).split(train_x)):\n",
    "        print('training fold...', kfold)\n",
    "\n",
    "        train_idx, valid_idx = tv_idx\n",
    "\n",
    "        model = Tt(seq_len=SEQ_LEN, feature_size=FEATURE_SIZE, output_size=OUTPUT_SIZE)\n",
    "\n",
    "        train_data_loader = make_data_loader(\n",
    "            train_x, train_idx, BATCH_SIZE, data_y=train_y, shuffle=True)\n",
    "        valid_data_loader = make_data_loader(\n",
    "            train_x, valid_idx, BATCH_SIZE, data_y=train_y, shuffle=False)\n",
    "\n",
    "        optimizer = paddle.optimizer.AdamW(learning_rate=1e-4, parameters=model.parameters())\n",
    "        criterion = paddle.nn.MSELoss()\n",
    "\n",
    "        epochs = EPOCHS # 训练轮次\n",
    "        save_dir = CKPT_DIR #训练过程中保存模型参数的文件夹\n",
    "        if not os.path.exists(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "\n",
    "        global_step = 0 #迭代次数\n",
    "        tic_train = time.time()\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        best_score = 0\n",
    "        for epoch in range(1+epoch_base, epochs+epoch_base+1):\n",
    "            for step, batch in enumerate(train_data_loader, start=1):\n",
    "                data = batch['data'].astype('float32')\n",
    "                label = batch['label'].astype('float32')\n",
    "\n",
    "                # 计算模型输出\n",
    "                output = model(inputs=data)\n",
    "                loss = criterion(output, label)\n",
    "                # print(loss)\n",
    "\n",
    "                # 打印损失函数值、准确率、计算速度\n",
    "                global_step += 1\n",
    "                if global_step % step_eval == 0:\n",
    "                    score = eval_model(model, valid_data_loader)            \n",
    "                    if score > best_score:\n",
    "                        # print('saving best model...', score)\n",
    "                        _save_dir = os.path.join(save_dir, '{}_kfold_{}_best_model.pdparams'.format(prefix, kfold))\n",
    "                        paddle.save(\n",
    "                            model.state_dict(),\n",
    "                            _save_dir)\n",
    "                        best_score = score\n",
    "                    if global_step % step_log == 0:\n",
    "                        print(\n",
    "                            'global step %d, epoch: %d, batch: %d, loss: %.5f, valid score: %.5f, speed: %.2f step/s'\n",
    "                            % (global_step, epoch, step, loss, score,\n",
    "                                10 / (time.time() - tic_train)))\n",
    "                        tic_train = time.time()\n",
    "\n",
    "                # 反向梯度回传，更新参数\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.clear_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T13:34:13.207397Z",
     "iopub.status.busy": "2022-09-28T13:34:13.207085Z",
     "iopub.status.idle": "2022-09-28T13:34:13.213056Z",
     "shell.execute_reply": "2022-09-28T13:34:13.212441Z",
     "shell.execute_reply.started": "2022-09-28T13:34:13.207379Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def do_pred(test_x, prefix):\n",
    "    print('-'*20)\n",
    "    print('predict ...', prefix)\n",
    "    print('predict x:', np.shape(test_x))\n",
    "\n",
    "    # 预测\n",
    "    test_data_loader = make_data_loader(\n",
    "            [test_x], [0], BATCH_SIZE, data_y=None, shuffle=False)\n",
    "\n",
    "    sub_df = []\n",
    "    save_dir = CKPT_DIR\n",
    "\n",
    "    for kfold in range(K_FOLD):\n",
    "        print('predict kfold...', kfold)\n",
    "        model = Tt(seq_len=SEQ_LEN, feature_size=FEATURE_SIZE, output_size=OUTPUT_SIZE)\n",
    "        model.set_dict(paddle.load(os.path.join(save_dir, '{}_kfold_{}_best_model.pdparams'.format(prefix, kfold))))\n",
    "        model.eval()\n",
    "\n",
    "        y_pred = []\n",
    "        for step, batch in enumerate(test_data_loader, start=1):\n",
    "            data = batch['data'].astype('float32')\n",
    "            label = batch['label'].astype('float32')\n",
    "\n",
    "            # 计算模型输出\n",
    "            output = model(inputs=data)\n",
    "            y_pred.extend(output.numpy())\n",
    "\n",
    "        sub_df.append(np.clip(y_pred, 0, None))\n",
    "    \n",
    "    return sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T13:34:13.214155Z",
     "iopub.status.busy": "2022-09-28T13:34:13.213850Z",
     "iopub.status.idle": "2022-09-28T13:46:49.641421Z",
     "shell.execute_reply": "2022-09-28T13:46:49.640252Z",
     "shell.execute_reply.started": "2022-09-28T13:34:13.214137Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "training ... m1\n",
      "train x: (2544, 168, 23) train y: (2544, 168, 20)\n",
      "training fold... 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0928 21:34:13.226250   365 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 11.2, Runtime API Version: 11.2\n",
      "W0928 21:34:13.229223   365 gpu_resources.cc:91] device: 0, cuDNN Version: 8.2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 100, epoch: 13, batch: 4, loss: 189.34042, valid score: 0.74267, speed: 0.67 step/s\n",
      "global step 200, epoch: 25, batch: 8, loss: 26.75570, valid score: 0.94225, speed: 0.75 step/s\n",
      "training fold... 1\n",
      "global step 100, epoch: 13, batch: 4, loss: 179.81596, valid score: 0.75175, speed: 0.88 step/s\n",
      "global step 200, epoch: 25, batch: 8, loss: 27.06740, valid score: 0.94496, speed: 0.75 step/s\n",
      "training fold... 2\n",
      "global step 100, epoch: 13, batch: 4, loss: 192.32230, valid score: 0.74129, speed: 0.91 step/s\n",
      "global step 200, epoch: 25, batch: 8, loss: 27.35677, valid score: 0.94298, speed: 0.75 step/s\n",
      "training fold... 3\n",
      "global step 100, epoch: 13, batch: 4, loss: 176.71466, valid score: 0.75317, speed: 0.87 step/s\n",
      "global step 200, epoch: 25, batch: 8, loss: 24.32207, valid score: 0.94430, speed: 0.75 step/s\n",
      "training fold... 4\n",
      "global step 100, epoch: 13, batch: 4, loss: 196.51141, valid score: 0.73796, speed: 0.88 step/s\n",
      "global step 200, epoch: 25, batch: 8, loss: 27.48337, valid score: 0.94143, speed: 0.74 step/s\n",
      "--------------------\n",
      "training ... m2\n",
      "train x: (2784, 168, 23) train y: (2784, 168, 20)\n",
      "training fold... 0\n",
      "global step 100, epoch: 12, batch: 1, loss: 192.12552, valid score: 0.74218, speed: 0.83 step/s\n",
      "global step 200, epoch: 23, batch: 2, loss: 26.67301, valid score: 0.94218, speed: 0.73 step/s\n",
      "training fold... 1\n",
      "global step 100, epoch: 12, batch: 1, loss: 181.16043, valid score: 0.75225, speed: 0.85 step/s\n",
      "global step 200, epoch: 23, batch: 2, loss: 26.28015, valid score: 0.94389, speed: 0.73 step/s\n",
      "training fold... 2\n",
      "global step 100, epoch: 12, batch: 1, loss: 194.71078, valid score: 0.74261, speed: 0.87 step/s\n",
      "global step 200, epoch: 23, batch: 2, loss: 28.19350, valid score: 0.93948, speed: 0.72 step/s\n",
      "training fold... 3\n",
      "global step 100, epoch: 12, batch: 1, loss: 181.40471, valid score: 0.75267, speed: 0.86 step/s\n",
      "global step 200, epoch: 23, batch: 2, loss: 27.63694, valid score: 0.94298, speed: 0.72 step/s\n",
      "training fold... 4\n",
      "global step 100, epoch: 12, batch: 1, loss: 194.80693, valid score: 0.73768, speed: 0.85 step/s\n",
      "global step 200, epoch: 23, batch: 2, loss: 27.04206, valid score: 0.93785, speed: 0.73 step/s\n",
      "--------------------\n",
      "training ... m3\n",
      "train x: (3480, 168, 23) train y: (3480, 168, 20)\n",
      "training fold... 0\n",
      "global step 100, epoch: 10, batch: 1, loss: 195.62051, valid score: 0.74132, speed: 0.80 step/s\n",
      "global step 200, epoch: 19, batch: 2, loss: 29.17942, valid score: 0.93782, speed: 0.70 step/s\n",
      "global step 300, epoch: 28, batch: 3, loss: 22.93004, valid score: 0.94732, speed: 0.90 step/s\n",
      "training fold... 1\n",
      "global step 100, epoch: 10, batch: 1, loss: 191.73341, valid score: 0.74899, speed: 0.85 step/s\n",
      "global step 200, epoch: 19, batch: 2, loss: 28.48909, valid score: 0.94111, speed: 0.70 step/s\n",
      "global step 300, epoch: 28, batch: 3, loss: 24.10351, valid score: 0.94549, speed: 0.83 step/s\n",
      "training fold... 2\n",
      "global step 100, epoch: 10, batch: 1, loss: 200.53751, valid score: 0.74166, speed: 0.84 step/s\n",
      "global step 200, epoch: 19, batch: 2, loss: 32.34964, valid score: 0.93378, speed: 0.70 step/s\n",
      "global step 300, epoch: 28, batch: 3, loss: 22.18238, valid score: 0.94529, speed: 0.86 step/s\n",
      "training fold... 3\n",
      "global step 100, epoch: 10, batch: 1, loss: 190.54114, valid score: 0.74929, speed: 0.83 step/s\n",
      "global step 200, epoch: 19, batch: 2, loss: 29.43060, valid score: 0.93647, speed: 0.70 step/s\n",
      "global step 300, epoch: 28, batch: 3, loss: 22.63792, valid score: 0.94633, speed: 0.84 step/s\n",
      "training fold... 4\n",
      "global step 100, epoch: 10, batch: 1, loss: 199.86848, valid score: 0.73911, speed: 0.82 step/s\n",
      "global step 200, epoch: 19, batch: 2, loss: 30.84038, valid score: 0.93401, speed: 0.71 step/s\n",
      "global step 300, epoch: 28, batch: 3, loss: 25.37951, valid score: 0.94664, speed: 0.82 step/s\n",
      "--------------------\n",
      "training ... m4\n",
      "train x: (3720, 168, 23) train y: (3720, 168, 20)\n",
      "training fold... 0\n",
      "global step 100, epoch: 9, batch: 4, loss: 196.55203, valid score: 0.74267, speed: 0.81 step/s\n",
      "global step 200, epoch: 17, batch: 8, loss: 31.35485, valid score: 0.93497, speed: 0.70 step/s\n",
      "global step 300, epoch: 25, batch: 12, loss: 24.27215, valid score: 0.94545, speed: 0.80 step/s\n",
      "training fold... 1\n",
      "global step 100, epoch: 9, batch: 4, loss: 191.64560, valid score: 0.74758, speed: 0.83 step/s\n",
      "global step 200, epoch: 17, batch: 8, loss: 30.92274, valid score: 0.93813, speed: 0.69 step/s\n",
      "global step 300, epoch: 25, batch: 12, loss: 24.90816, valid score: 0.94470, speed: 0.90 step/s\n",
      "training fold... 2\n",
      "global step 100, epoch: 9, batch: 4, loss: 197.55722, valid score: 0.74337, speed: 0.84 step/s\n",
      "global step 200, epoch: 17, batch: 8, loss: 31.99613, valid score: 0.93345, speed: 0.70 step/s\n",
      "global step 300, epoch: 25, batch: 12, loss: 24.23726, valid score: 0.94481, speed: 0.77 step/s\n",
      "training fold... 3\n",
      "global step 100, epoch: 9, batch: 4, loss: 186.58867, valid score: 0.74806, speed: 0.79 step/s\n",
      "global step 200, epoch: 17, batch: 8, loss: 29.82816, valid score: 0.93393, speed: 0.71 step/s\n",
      "global step 300, epoch: 25, batch: 12, loss: 25.93081, valid score: 0.94440, speed: 0.84 step/s\n",
      "training fold... 4\n",
      "global step 100, epoch: 9, batch: 4, loss: 198.73732, valid score: 0.74012, speed: 0.81 step/s\n",
      "global step 200, epoch: 17, batch: 8, loss: 31.71860, valid score: 0.92987, speed: 0.70 step/s\n",
      "global step 300, epoch: 25, batch: 12, loss: 24.98176, valid score: 0.94471, speed: 0.83 step/s\n"
     ]
    }
   ],
   "source": [
    "# 依次训练每个测试集对应的模型\n",
    "do_train(train_x_1, train_y_1, 'm1')\n",
    "do_train(train_x_2, train_y_2, 'm2')\n",
    "do_train(train_x_3, train_y_3, 'm3')\n",
    "do_train(train_x_4, train_y_4, 'm4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T13:46:49.643791Z",
     "iopub.status.busy": "2022-09-28T13:46:49.643427Z",
     "iopub.status.idle": "2022-09-28T13:46:55.684612Z",
     "shell.execute_reply": "2022-09-28T13:46:55.683728Z",
     "shell.execute_reply.started": "2022-09-28T13:46:49.643754Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "predict ... m1\n",
      "predict x: (168, 23)\n",
      "predict kfold... 0\n",
      "predict kfold... 1\n",
      "predict kfold... 2\n",
      "predict kfold... 3\n",
      "predict kfold... 4\n",
      "--------------------\n",
      "predict ... m2\n",
      "predict x: (168, 23)\n",
      "predict kfold... 0\n",
      "predict kfold... 1\n",
      "predict kfold... 2\n",
      "predict kfold... 3\n",
      "predict kfold... 4\n",
      "--------------------\n",
      "predict ... m3\n",
      "predict x: (168, 23)\n",
      "predict kfold... 0\n",
      "predict kfold... 1\n",
      "predict kfold... 2\n",
      "predict kfold... 3\n",
      "predict kfold... 4\n",
      "--------------------\n",
      "predict ... m4\n",
      "predict x: (168, 23)\n",
      "predict kfold... 0\n",
      "predict kfold... 1\n",
      "predict kfold... 2\n",
      "predict kfold... 3\n",
      "predict kfold... 4\n"
     ]
    }
   ],
   "source": [
    "# 以此预测数据\n",
    "pred_1 = do_pred(test_x_1, 'm1')\n",
    "pred_2 = do_pred(test_x_2, 'm2')\n",
    "pred_3 = do_pred(test_x_3, 'm3')\n",
    "pred_4 = do_pred(test_x_4, 'm4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = np.vstack((\n",
    "    np.mean(pred_1, axis=0).squeeze(),\n",
    "    np.mean(pred_2, axis=0).squeeze(),\n",
    "    np.mean(pred_3, axis=0).squeeze(),\n",
    "    np.mean(pred_4, axis=0).squeeze()))\n",
    "\n",
    "result[result<0] = 0\n",
    "result = pd.concat([df_sub['time'], pd.DataFrame(result)], axis=1)\n",
    "result.columns = df_sub.columns\n",
    "result.to_csv('data/result_0929_1.csv', index=False, encoding='utf-8')\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
